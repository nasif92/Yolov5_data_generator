{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# All necessary imports\n",
        "from __future__ import print_function, division\n",
        "\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "LQtoVY63G8b1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/train_X.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXgKx2uLJyLo",
        "outputId": "e019fc36-2054-499b-ab6a-9a00b4fccc1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/train_X.zip\n",
            "replace train_X.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: train_X.npy             \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/train_X.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFOzfq4ZRBsj",
        "outputId": "cbba036f-3582-4e0e-d826-aa81d784fa14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/train_X.zip\n",
            "replace train_X.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: r\n",
            "new name: training_X\n",
            "  inflating: training_X              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7RqAkf5G-is",
        "outputId": "d9c33b2b-cbfa-4bdc-d965-090ebba1b635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dl83X-gNGr3T",
        "outputId": "3d5f0834-e1f9-49ff-c117-3bf4c6a1894c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images: torch.Size([55000, 3, 64, 64]) torch.Size([5000, 3, 64, 64])\n",
            "Y train and validation torch.Size([55000, 2]) torch.Size([5000, 2])\n",
            "Bounding boxes:  torch.Size([55000, 2, 4]) torch.Size([5000, 2, 4])\n"
          ]
        }
      ],
      "source": [
        "#LOAD DATA\n",
        "# Lists of hyperparameters here\n",
        "# Feel free to add more if needed\n",
        "batch_size = 128\n",
        "validate_every = 1\n",
        "lr = 1e-3\n",
        "weight_decay = 5e-3\n",
        "epochs = 20\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "file_path = \"/content\"\n",
        "x_train = torch.tensor(np.load(file_path + \"/train_X.npy\"))\n",
        "\n",
        "x_np = np.load(file_path + \"/train_X.npy\")\n",
        "x_train = x_train.view(55000, 3, 64, 64)\n",
        "x_validation = torch.tensor(np.load(file_path + \"/valid_X.npy\"))\n",
        "validation_np = np.load(file_path + \"/valid_X.npy\")\n",
        "\n",
        "x_validation = x_validation.view(5000, 3, 64, 64)\n",
        "print(\"Images:\", x_train.shape, x_validation.shape)\n",
        "\n",
        "y_train = torch.tensor(np.load(file_path + \"/train_Y.npy\")).type(torch.LongTensor)\n",
        "y_validation = torch.tensor(np.load(file_path + \"/valid_Y.npy\")).type(torch.LongTensor)\n",
        "print(\"Y train and validation\", y_train.shape, y_validation.shape)\n",
        "      \n",
        "train_bboxes = torch.Tensor(np.load(file_path + \"/train_bboxes.npy\")).type(torch.LongTensor)\n",
        "valid_bboxes = torch.Tensor(np.load(file_path + \"/valid_bboxes.npy\")).type(torch.LongTensor)\n",
        "\n",
        "\n",
        "print(\"Bounding boxes: \",train_bboxes.shape, valid_bboxes.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WR4I_f_tHAvU",
        "outputId": "4abfc0dd-7380-45e8-a1ac-f7c429a8083f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 v6.2-228-g6ae3dff Python-3.7.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 22.6/78.2 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "from PIL import Image\n",
        "\n",
        "for i in range(55000):\n",
        "  src_img = x_np[i].squeeze().reshape((64, 64, 3)).astype(np.uint8)\n",
        "  im = Image.fromarray(src_img)\n",
        "  im.save(\"/content/train_data/images/train/\" + str(i) + \".png\")\n",
        "\n",
        "for i in range(5000):\n",
        "  src_img = validation_np[i].squeeze().reshape((64, 64, 3)).astype(np.uint8)\n",
        "  im = Image.fromarray(src_img)\n",
        "  im.save(\"/content/train_data/images/val/\" + str(i) + \".png\")"
      ],
      "metadata": {
        "id": "FVAiIuF3Iepx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert(y1, x1, y2, x2, image_w, image_h):\n",
        "    return [((x2 + x1)/(2*image_w)) * 0.4375, ((y2 + y1)/(2*image_h))* 0.4375, (x2 - x1)/image_w* 0.4375, (y2 - y1)/image_h* 0.4375]"
      ],
      "metadata": {
        "id": "Qjv4zmiNUCT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LABELS"
      ],
      "metadata": {
        "id": "UVBmXPHcUD6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_bboxes = []\n",
        "import tensorflow as tf\n",
        "\n",
        "for i in range(55000):\n",
        "  w= 28\n",
        "  h= 28\n",
        "  d1 = train_bboxes[i][0].numpy()\n",
        "  d2 = train_bboxes[i][1].numpy()\n",
        "  _d1 =list(convert(d1[0], d1[1], d1[2], d1[3], w, h))\n",
        "  _d2 = list(convert(d2[0], d2[1], d2[2], d2[3], w, h))\n",
        "  a, b = y_train[i][0].view(1).numpy(), y_train[i][1].view(1).numpy()\n",
        "  _d1.insert(0, a[0])\n",
        "  _d2.insert(0, b[0])\n",
        "\n",
        "  str1 = \" \".join(map(str,_d1))\n",
        "  fin = str1 + \"\\n\" + \" \".join(map(str, _d2))\n",
        "  x_bboxes.append(fin)\n",
        "  \n",
        "  # just to test the 52000th img\n",
        "  if i == 54999:\n",
        "    print(x_bboxes[i])\n",
        "\n",
        "len(x_bboxes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCobJPTNUDjL",
        "outputId": "1964bf6c-de6e-4993-eb3e-08a6af8e59c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 0.34375 0.640625 0.4375 0.4375\n",
            "7 0.671875 0.734375 0.4375 0.4375\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55000"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_bboxes = []\n",
        "import tensorflow as tf\n",
        "\n",
        "for i in range(5000):\n",
        "  w= 28\n",
        "  h= 28\n",
        "  d1 = valid_bboxes[i][0].numpy()\n",
        "  d2 = valid_bboxes[i][1].numpy()\n",
        "  _d1 =list(convert(d1[0], d1[1], d1[2], d1[3], w, h))\n",
        "  _d2 = list(convert(d2[0], d2[1], d2[2], d2[3], w, h))\n",
        "\n",
        "  a, b = y_validation[i][0].view(1).numpy(), y_validation[i][1].view(1).numpy()\n",
        "\n",
        "  _d1.insert(0, a[0])\n",
        "  _d2.insert(0, b[0])\n",
        "\n",
        "  str1 = \" \".join(map(str,_d1))\n",
        "  fin = str1 + \"\\n\" + \" \".join(map(str, _d2))\n",
        "  val_bboxes.append(fin)\n",
        "\n",
        "  # just to test the 4900th img\n",
        "  if i == 0:\n",
        "    print(val_bboxes[i])\n",
        "    # plt.imshow(validation_images[i])\n",
        "\n",
        "len(val_bboxes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQDphUlRUK_8",
        "outputId": "a80ac972-2b49-408c-bffc-4e770eee0780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 0.578125 0.703125 0.4375 0.4375\n",
            "5 0.78125 0.734375 0.4375 0.4375\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5000):\n",
        "  with open(r'/content/train_data/labels/val/' + str(i) + '.txt', 'w') as fp:\n",
        "\n",
        "    # write each item on a new line\n",
        "      fp.write(\"%s\\n\" % val_bboxes[i])\n",
        "print('Done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zhiwAU7VLbi",
        "outputId": "a8209049-6eb0-45a8-bc11-28f7b696a0da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(55000):\n",
        "  with open(r'/content/train_data/labels/train/' + str(i) + '.txt', 'w') as fp:\n",
        "\n",
        "    # write each item on a new line\n",
        "      fp.write(\"%s\\n\" % x_bboxes[i])\n",
        "print('Done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLosSDKpVOg0",
        "outputId": "52b0f3a4-2f20-4fae-b92a-dbabeea75ffb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 640 --batch 40 --epochs 30 --data custom_data.yaml --weights yolov5s.pt "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOjTR2nPHDUk",
        "outputId": "8bafb283-9a11-4ac5-b645-b9c5867a4edc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=custom_data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=30, batch_size=40, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "Command 'git fetch origin' timed out after 5 seconds\n",
            "YOLOv5 🚀 v6.2-228-g6ae3dff Python-3.7.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=0.0, translate=0.0, scale=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=10\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     40455  models.yolo.Detect                      [10, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7046599 parameters, 7046599 gradients, 16.0 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.000625), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/train_data/labels/train.cache' images and labels... 55000 found, 0 missing, 0 empty, 0 corrupt: 100% 55000/55000 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/train_data/images/train/11290.png: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/train_data/images/train/15247.png: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/train_data/images/train/31900.png: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/train_data/images/train/54614.png: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/train_data/images/train/54735.png: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/train_data/labels/val.cache' images and labels... 5000 found, 0 missing, 0 empty, 0 corrupt: 100% 5000/5000 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.00 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/exp2/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp2\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/29      9.13G   0.009606   0.008807    0.01055         80        640: 100% 1375/1375 [10:41<00:00,  2.14it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 63/63 [00:48<00:00,  1.31it/s]\n",
            "                   all       5000      10000      0.988      0.954      0.986      0.936\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/29      11.4G   0.005111   0.003411   0.001592         80        640: 100% 1375/1375 [10:40<00:00,  2.15it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 63/63 [00:46<00:00,  1.35it/s]\n",
            "                   all       5000      10000       0.99      0.984      0.994      0.979\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/29      11.4G   0.004235   0.002445   0.001198         80        640: 100% 1375/1375 [10:33<00:00,  2.17it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 63/63 [00:46<00:00,  1.36it/s]\n",
            "                   all       5000      10000      0.994      0.986      0.995      0.984\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/29      11.4G   0.003389   0.001794  0.0009852         80        640: 100% 1375/1375 [10:25<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 63/63 [00:46<00:00,  1.36it/s]\n",
            "                   all       5000      10000      0.995      0.989      0.995      0.985\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/29      11.4G   0.002746   0.001444  0.0007814         80        640: 100% 1375/1375 [10:25<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 63/63 [00:46<00:00,  1.36it/s]\n",
            "                   all       5000      10000      0.997      0.991      0.995       0.98\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/29      11.4G   0.002392   0.001226  0.0006578         80        640: 100% 1375/1375 [10:24<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 63/63 [00:46<00:00,  1.36it/s]\n",
            "                   all       5000      10000      0.996      0.993      0.995      0.973\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/29      11.4G   0.002187   0.001133  0.0006101         80        640: 100% 1375/1375 [10:25<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 63/63 [00:45<00:00,  1.37it/s]\n",
            "                   all       5000      10000          1      0.977      0.994      0.966\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/29      11.4G   0.002008   0.001023   0.000547         80        640: 100% 1375/1375 [10:25<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 63/63 [00:46<00:00,  1.36it/s]\n",
            "                   all       5000      10000      0.997      0.994      0.995      0.969\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/29      11.4G   0.001882  0.0009524  0.0005125         80        640: 100% 1375/1375 [10:25<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 63/63 [00:46<00:00,  1.36it/s]\n",
            "                   all       5000      10000      0.998      0.994      0.995      0.964\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/29      11.4G   0.001795  0.0009247  0.0004973         80        640: 100% 1375/1375 [10:26<00:00,  2.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 63/63 [00:46<00:00,  1.37it/s]\n",
            "                   all       5000      10000      0.997      0.995      0.995      0.965\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/29      11.4G   0.001699  0.0008696  0.0004648         80        640: 100% 1375/1375 [10:26<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 63/63 [00:46<00:00,  1.36it/s]\n",
            "                   all       5000      10000      0.999      0.994      0.995      0.965\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/29      11.4G    0.00163  0.0008362  0.0004463         80        640: 100% 1375/1375 [10:26<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 63/63 [00:46<00:00,  1.37it/s]\n",
            "                   all       5000      10000      0.998      0.994      0.995       0.96\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/29      11.4G    0.00156  0.0007933  0.0004299         80        640: 100% 1375/1375 [10:26<00:00,  2.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 63/63 [00:46<00:00,  1.36it/s]\n",
            "                   all       5000      10000      0.998      0.994      0.995       0.96\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/29      11.4G   0.001493  0.0007671  0.0004086         80        640: 100% 1375/1375 [10:26<00:00,  2.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 63/63 [00:46<00:00,  1.35it/s]\n",
            "                   all       5000      10000      0.998      0.995      0.995       0.96\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/29      11.4G   0.001438  0.0007285   0.000393         80        640: 100% 1375/1375 [10:26<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 63/63 [00:46<00:00,  1.35it/s]\n",
            "                   all       5000      10000      0.999      0.994      0.995      0.962\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/29      11.4G   0.001379   0.000717  0.0003926         80        640: 100% 1375/1375 [10:26<00:00,  2.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 63/63 [00:46<00:00,  1.35it/s]\n",
            "                   all       5000      10000      0.998      0.995      0.995      0.961\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/29      11.4G   0.001328  0.0006993  0.0003825         80        640: 100% 1375/1375 [10:26<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 63/63 [00:46<00:00,  1.35it/s]\n",
            "                   all       5000      10000      0.999      0.994      0.995      0.959\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/29      11.4G   0.001262  0.0006489  0.0003632         80        640: 100% 1375/1375 [10:25<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 63/63 [00:46<00:00,  1.36it/s]\n",
            "                   all       5000      10000      0.998      0.994      0.995      0.958\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/29      11.4G   0.001201  0.0006321  0.0003487         80        640: 100% 1375/1375 [10:25<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 63/63 [00:45<00:00,  1.37it/s]\n",
            "                   all       5000      10000      0.998      0.995      0.995       0.96\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/29      11.4G   0.001157  0.0006307  0.0003498         80        640: 100% 1375/1375 [10:25<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 63/63 [00:45<00:00,  1.38it/s]\n",
            "                   all       5000      10000      0.999      0.994      0.995      0.955\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/29      11.4G   0.001099  0.0005848  0.0003334         80        640: 100% 1375/1375 [10:25<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 63/63 [00:45<00:00,  1.37it/s]\n",
            "                   all       5000      10000      0.999      0.994      0.995      0.951\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/29      11.4G   0.001031    0.00054  0.0003168         80        640: 100% 1375/1375 [10:24<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 63/63 [00:45<00:00,  1.38it/s]\n",
            "                   all       5000      10000      0.999      0.994      0.995       0.95\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/29      11.4G  0.0009693    0.00051  0.0003062         80        640: 100% 1375/1375 [10:24<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 63/63 [00:45<00:00,  1.38it/s]\n",
            "                   all       5000      10000      0.999      0.994      0.995      0.951\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/29      11.4G  0.0009112  0.0004818  0.0002926         80        640: 100% 1375/1375 [10:24<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 63/63 [00:46<00:00,  1.37it/s]\n",
            "                   all       5000      10000      0.999      0.995      0.995      0.952\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/29      11.4G  0.0008491  0.0004522  0.0002828         80        640: 100% 1375/1375 [10:24<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 63/63 [00:45<00:00,  1.37it/s]\n",
            "                   all       5000      10000      0.998      0.995      0.995      0.953\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/29      11.4G  0.0007713  0.0004146  0.0002699         80        640: 100% 1375/1375 [10:23<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 63/63 [00:45<00:00,  1.37it/s]\n",
            "                   all       5000      10000      0.998      0.995      0.995      0.953\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/29      11.4G  0.0006957  0.0003795  0.0002571         80        640: 100% 1375/1375 [10:23<00:00,  2.21it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 63/63 [00:46<00:00,  1.36it/s]\n",
            "                   all       5000      10000      0.998      0.995      0.995      0.953\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/29      11.4G  0.0006165  0.0003387  0.0002442         80        640: 100% 1375/1375 [10:22<00:00,  2.21it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 63/63 [00:45<00:00,  1.38it/s]\n",
            "                   all       5000      10000      0.998      0.995      0.995      0.953\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/29      11.4G  0.0005333  0.0002975   0.000231         80        640: 100% 1375/1375 [10:22<00:00,  2.21it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 63/63 [00:45<00:00,  1.38it/s]\n",
            "                   all       5000      10000      0.998      0.995      0.995      0.954\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/29      11.4G   0.000422  0.0002402  0.0002065         80        640:  25% 343/1375 [02:35<07:44,  2.22it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "myXNv3MgXVXy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
